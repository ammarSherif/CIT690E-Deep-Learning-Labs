{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ammarSherif/CIT690E-Deep-Learning-Labs/blob/main/Lab%202%3A%20Tensor%20Operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNs5vHFi5wZa"
      },
      "source": [
        "# Lab 2: Tensor Oprations\n",
        "CIT690E: Deep Learning<br>\n",
        "Nile University<br>\n",
        "Ammar Sherif<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDlWWB7p5wZb"
      },
      "source": [
        "## Acknowledgement\n",
        "Kindly, notice this notebook is adapted from Eng. Ahmed's version; you can check his [GitHub repo](https://github.com/ahosnyyy/CIT690E-DL-Course)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6xhcihAbzkv"
      },
      "source": [
        "## PyTorch\n",
        "- Open-source by Facebook\n",
        "- Optimized Deep Learning on GPU and CPU\n",
        "- Supports Python, C++, and Java\n",
        "- Products built upon it: \n",
        "    - Tesla Autopilot\n",
        "    - Uber’s Pyro\n",
        "    - Hugging Face’s Transformers\n",
        "    - PyTorch Lightning\n",
        "    - Catalyst\n",
        "- Primary structure: Tensors\n",
        "You can check more details in their [PyTorch Website](https://pytorch.org/) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YfkOhuBc65i"
      },
      "source": [
        "## PyTorch Tensors\n",
        "They represent **n-dimensional arrays**. It is very similar to NumPy arrays. Therefore, we have\n",
        "- scalars: `rank 0` tensors\n",
        "- 1D vector: `rank 1` tensors\n",
        "- 2D Matrix: `rank 2` tensors\n",
        "- nth-dimentional structure: `rank n` tensors\n",
        "\n",
        "![tensor_1](https://d3i71xaburhd42.cloudfront.net/82750a1533ca30a705d3325290ee8de471073773/3-Figure3-1.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W4zZH1lNqHAZ"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Some imports\n",
        "# ==============================================================================\n",
        "import torch\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hUlX_Gsn949"
      },
      "source": [
        "## Creating Tensors\n",
        "\n",
        "### Empty Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eMsRFThp0jf",
        "outputId": "ef03c1f8-d393-472b-e09d-a9c5b035cde9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[-5.7061e-06,  3.0726e-41,  3.3631e-44,  0.0000e+00],\n",
            "        [        nan,  3.0726e-41,  1.1578e+27,  1.1362e+30],\n",
            "        [ 7.1547e+22,  4.5828e+30,  1.2121e+04,  7.1846e+22]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Below we use the empty to generate 3*4 tensor\n",
        "# ==============================================================================\n",
        "x = torch.empty(3, 4)\n",
        "print(type(x))\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASjV0VhqqXcj"
      },
      "source": [
        "**Some Notes**\n",
        "- we used the `empty()` from `torch`\n",
        "- we specified `3` as the number of rows and `4` as the number of columns\n",
        "- the datatype is `torch.FloatTensor` by default\n",
        "- the data are random, as they are in memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQNsrqZXpd4D"
      },
      "source": [
        "### From a List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MknRPN6hb8DI",
        "outputId": "20bae0a6-61f0-4ca2-a6fa-4414f0ed0208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Generate a 1D tensor of the below data\n",
        "# ==============================================================================\n",
        "a = torch.tensor([1, 2, 3])\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIa56-iJrZxs",
        "outputId": "694f197e-0b3f-43b7-dead-ac06f64c88ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Generate 2D tensor from a 2D list\n",
        "# ==============================================================================\n",
        "b = torch.tensor([[1], [2], [3]])\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfCp60Zfuzic"
      },
      "source": [
        "### From a NumPy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-TGE-YLQvDgV"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Import numpy creating an array; then, convert it to tensor\n",
        "# ==============================================================================\n",
        "import numpy as np\n",
        "\n",
        "na = np.array([1, 2, 3])\n",
        "a = torch.tensor(na)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKgHDU0jvI9V"
      },
      "source": [
        "We can also use the <font color='red'>`from_numpy`</font> function to convert a NumPy array to a PyTorch tensor. You just have to pass the NumPy array object as an argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CSRXYE50vYJx"
      },
      "outputs": [],
      "source": [
        "b = torch.from_numpy(na)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63cvjAtbvb4o"
      },
      "source": [
        "### Special Tensors\n",
        "\n",
        "- `eye()`: Identity 2D Tensor\n",
        "- `ones()`: Tensor of ones of a particular shape\n",
        "- `zeros()`: Tensor of zeros of a particular shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiHZo_EXwK82",
        "outputId": "eb1ae2f9-f305-4aee-85be-f058c73179f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Create a identity tensor with 3*3 shape.\n",
        "# ==============================================================================\n",
        "eys = torch.eye(3)\n",
        "print(eys)\n",
        "# ==============================================================================\n",
        "# Create a tensor with 2*2 shape whose values are all 1.\n",
        "# ==============================================================================\n",
        "ones = torch.ones((2, 2))\n",
        "print(ones)\n",
        "# ==============================================================================\n",
        "# Create a tensor with 3*3 shape whose values are all 0.\n",
        "# ==============================================================================\n",
        "zeros = torch.zeros((3, 3))\n",
        "print(zeros)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2Jgpq2mwZvB"
      },
      "source": [
        "### Random Tensors\n",
        "\n",
        "- `rand()`: sampled from a uniform distribution\n",
        "- `randn()`: sampled from a normal distribution with mean 0 and variance 1\n",
        "- `randint()`: random samples of integer values in a particular range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V08SyMYxR_q",
        "outputId": "568018da-46a7-4714-8702-1a87a1f8437a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7182, 0.4727, 0.1787, 0.4787, 0.3208, 0.7863, 0.6366, 0.9392, 0.1751,\n",
            "        0.5948])\n",
            "************************************************\n",
            "tensor([[0.6633],\n",
            "        [0.9657],\n",
            "        [0.5947],\n",
            "        [0.3833],\n",
            "        [0.3941],\n",
            "        [0.1457],\n",
            "        [0.1393],\n",
            "        [0.8865],\n",
            "        [0.3315],\n",
            "        [0.8517]])\n",
            "************************************************\n",
            "tensor([[0.0945, 0.9145],\n",
            "        [0.2471, 0.7188]])\n",
            "************************************************\n",
            "tensor([[ 1.0202,  0.7952],\n",
            "        [-0.0992,  1.2636]])\n",
            "************************************************\n",
            "tensor([[0, 0, 5],\n",
            "        [1, 9, 4],\n",
            "        [2, 5, 1]])\n",
            "************************************************\n",
            "tensor([[9, 9, 6],\n",
            "        [7, 9, 6],\n",
            "        [5, 6, 8]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Create a tensor with 1*10 shape with random value between 0 and 1\n",
        "r0 = torch.rand(10)\n",
        "print(r0)\n",
        "print(\"************************************************\")\n",
        "# Create a tensor with 10*1 shape with random value between 0 and 1\n",
        "r1 = torch.rand((10, 1))\n",
        "print(r1)\n",
        "print(\"************************************************\")\n",
        "# Create a tensor with 2*2 shape with random value between 0 and 1\n",
        "r2 = torch.rand((2, 2))\n",
        "print(r2)\n",
        "print(\"************************************************\")\n",
        "# Create a tensor with 2*2 shape with random value from a normal distribution.\n",
        "r3 = torch.randn((2,2))\n",
        "print(r3)\n",
        "print(\"************************************************\")\n",
        "# Create an integer type tensor with 3*3 shape with random value between 0 and 10.\n",
        "r4 = torch.randint(high=10, size=(3, 3))\n",
        "print(r4)\n",
        "print(\"************************************************\")\n",
        "# Create an integer type tensor with 3*3 shape with random value between 5 and 10.\n",
        "r5 = torch.randint(low=5, high=10, size=(3, 3))\n",
        "print(r5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYcc2oOwyL_S"
      },
      "source": [
        "#### Seeding\n",
        "You can use `torch.manual_seed()` to manually select a particular seed. This is very helpful for **reproducability**. Hence, we can reproduce the results produced by a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOQMBOmAyJEW",
        "outputId": "258d634f-b3b8-46a3-a182-23bb585d78db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3126, 0.3791, 0.3087],\n",
            "        [0.0736, 0.4216, 0.0691]])\n",
            "tensor([[0.2332, 0.4047, 0.2162],\n",
            "        [0.9927, 0.4128, 0.5938]])\n",
            "tensor([[0.3126, 0.3791, 0.3087],\n",
            "        [0.0736, 0.4216, 0.0691]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Manual seeding to re-produce the tensors\n",
        "# ==============================================================================\n",
        "torch.manual_seed(1729)\n",
        "random1 = torch.rand(2, 3)\n",
        "print(random1)\n",
        "\n",
        "random2 = torch.rand(2, 3)\n",
        "print(random2)\n",
        "\n",
        "torch.manual_seed(1729)\n",
        "random3 = torch.rand(2, 3)\n",
        "print(random3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ9YenN-5wZo",
        "outputId": "13da66f4-e3be-449f-ec6a-7ae2b348827e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2332, 0.4047, 0.2162],\n",
            "        [0.9927, 0.4128, 0.5938]])\n"
          ]
        }
      ],
      "source": [
        "random4 = torch.rand(2, 3)\n",
        "print(random4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h0gbmKExWP5"
      },
      "source": [
        "### Using range\n",
        "We can create a tensor from a range where the `start` is included, yet the `end` is excluded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKb7Mb195wZp",
        "outputId": "777a9ca8-effe-4651-d7a6-b89028ca2e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Use arange to generate a sequence [1-9]\n",
        "# ==============================================================================\n",
        "a = torch.arange(1, 10)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErvOA1smysZO"
      },
      "source": [
        "### From Tensor Shapes\n",
        "- `torch.empty_like()`\n",
        "- `torch.zeros_like()`\n",
        "- `torch.ones_like()`\n",
        "- `torch.rand_like()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ29u3e_yxWv",
        "outputId": "4f76302d-27a0-46bb-ab2f-f8e20d6f4886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3])\n",
            "tensor([[[-5.7067e-06,  3.0726e-41,  3.3631e-44],\n",
            "         [ 0.0000e+00,         nan,  5.9382e-01]],\n",
            "\n",
            "        [[ 1.1578e+27,  1.1362e+30,  7.1547e+22],\n",
            "         [ 4.5828e+30,  1.2121e+04,  7.1846e+22]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[-5.7067e-06,  3.0726e-41,  3.3631e-44],\n",
            "         [ 0.0000e+00,         nan,  1.5912e+00]],\n",
            "\n",
            "        [[ 1.1578e+27,  1.1362e+30,  7.1547e+22],\n",
            "         [ 4.5828e+30,  1.2121e+04,  7.1846e+22]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[1., 1., 1.],\n",
            "         [1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1.],\n",
            "         [1., 1., 1.]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[0.6128, 0.1519, 0.0453],\n",
            "         [0.5035, 0.9978, 0.3884]],\n",
            "\n",
            "        [[0.6929, 0.1703, 0.1384],\n",
            "         [0.4759, 0.7481, 0.0361]]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Generate an empty tensor whose shape is 2*2*3. \n",
        "# ==============================================================================\n",
        "x = torch.empty(2, 2, 3)\n",
        "print(x.shape)\n",
        "print(x)\n",
        "\n",
        "# ==============================================================================\n",
        "# Now, use the above tensor, x, to create new tensors using the functions above.\n",
        "# ==============================================================================\n",
        "empty_like_x = torch.empty_like(x)\n",
        "print(empty_like_x.shape)\n",
        "print(empty_like_x)\n",
        "\n",
        "zeros_like_x = torch.zeros_like(x)\n",
        "print(zeros_like_x.shape)\n",
        "print(zeros_like_x)\n",
        "\n",
        "ones_like_x = torch.ones_like(x)\n",
        "print(ones_like_x.shape)\n",
        "print(ones_like_x)\n",
        "\n",
        "rand_like_x = torch.rand_like(x)\n",
        "print(rand_like_x.shape)\n",
        "print(rand_like_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIhLG929zLg6"
      },
      "source": [
        "## Tensor Metadate\n",
        "\n",
        "### Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq_YJrkYyroi",
        "outputId": "95b4f63c-5483-447c-9626-b26336cbb632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Use dtype to sepcify the datatype\n",
        "# ==============================================================================\n",
        "a = torch.tensor([1, 2, 3], dtype=torch.float)\n",
        "print(a.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2npQOT61PDV"
      },
      "source": [
        "### Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoNBsowA1fWn",
        "outputId": "61971fe0-eab7-4e27-f169-8b036e679e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4])\n",
            "torch.Size([3, 4])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# We can get the use with the use of shape or size()\n",
        "# ==============================================================================\n",
        "a = torch.ones((3, 4))\n",
        "print(a.shape)\n",
        "print(a.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWegmPxZ1ujh"
      },
      "source": [
        "### Dimension Number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnbyCt4p19vh",
        "outputId": "9205408f-7aaa-48d1-cab4-953145fe8a0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Get the number of dimensions via ndim or dim()\n",
        "# ==============================================================================\n",
        "a = torch.ones((3, 4, 6))\n",
        "print(a.ndim)\n",
        "print(a.dim())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRLhWkQ54XYy"
      },
      "source": [
        "### Elements Number "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KBzGqXM4sCu",
        "outputId": "0c302113-2116-4c99-aa64-c3c9e06f54c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Use numel to get the total number of elements in a tensor\n",
        "# ==============================================================================\n",
        "a = torch.ones((3, 4, 6))\n",
        "print(a.numel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aVWaosQ4u-n"
      },
      "source": [
        "## Tensor Types\n",
        "\n",
        "Some common types listed below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECWIzNz-5Hl5"
      },
      "source": [
        "| Data Type  | dtype | CPU tensor | GPU tensor |\n",
        "| --- | --- | --- |---|\n",
        "| 32-bit floating point | torch.float32/torch.float | torch.FloatTensor | torch.cuda.FloatTensor |\n",
        "|64-bit floating point|torch.float64/torch.double|torch.DoubleTensor|torch.cuda.DoubleTensor|\n",
        "|8-bit integer (signed)|torch.int16|torch.ShortTensor|torch.cuda.ShortTensor|\n",
        "|boolean|torch.bool|torch.BoolTensor|torch.cuda.BoolTensor|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdKYSGyG6p1d"
      },
      "source": [
        "Importance of Tensor Types:\n",
        "\n",
        "- **speed and memory usage**.<br>For example, a matrix <font color='red'>`A`</font> with size 1000x1000. If the <font color='red'>`dtype`</font> is <font color='red'>`torch.float32`</font>, this matrix would consume about **3.81MB GPU memory** (1000x1000x4bytes, each <font color='red'>`float32`</font> uses 4 bytes.). If the <font color='red'>`dtype`</font> is <font color='red'>`torch.double`</font>, this matrix would consume about **7.62MB GPU memory** (1000x1000x8bytes, each <font color='red'>`double`</font> uses 8 bytes.).\n",
        "\n",
        "- API Requirement<br>Check this [example](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u00vO5Tc8OBa"
      },
      "source": [
        "### Tensors of particular types\n",
        "\n",
        "- <font color='red'>`FloatTensor`</font>: float32\n",
        "- <font color='red'>`IntTensor`</font>\n",
        "- <font color='red'>`DoubleTensor`</font>: float64\n",
        "- <font color='red'>`LongTensor`</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2rJdW8DS6mwp"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Create a tensor of floats and another one of integers\n",
        "# ==============================================================================\n",
        "d = torch.FloatTensor([1, 2, 3])\n",
        "e = torch.IntTensor([1, 2, 3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHjRc7Vd8-Zj"
      },
      "source": [
        "### Casting between tensor types\n",
        "\n",
        "The Tensor class has the method <font color='red'>`to()`</font>, which can cast tensors into different types. To cast a tensor, call its <font color='red'>`to()`</font> method and pass the dtype as the argument, as shown in the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4otQZVx786Q2",
        "outputId": "344c9fe9-5cd2-4bdf-dcfc-9cb4bbd68394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dtype for b is torch.float32\n",
            "The dtype for c is torch.int64\n"
          ]
        }
      ],
      "source": [
        "b = torch.tensor([1, 2, 3], dtype=torch.float)\n",
        "print(\"The dtype for b is {}\".format(b.dtype))\n",
        "\n",
        "c = b.to(dtype=torch.int64)\n",
        "print(\"The dtype for c is {}\".format(c.dtype))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUbuS4gM9Sk3"
      },
      "source": [
        "**Notice**: The <font color='red'>`to()`</font> cast is **not an in-place operation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je_id49-9qXG"
      },
      "source": [
        "## Accessing Elements\n",
        "\n",
        "### Using Index\n",
        "\n",
        "If you are already familiar with the NumPy array, you can use the same methods to select tensors by <font color='red'>`[]`</font> operations.\n",
        "\n",
        "Take a 2-dimensional tensor as an example. Let’s consider it as a matrix.\n",
        "\n",
        "* <font color='red'>`tensor[2, 3]`</font>: Get only one value.\n",
        "* <font color='red'>`tensor[:, 1]`</font>: Get the second column from the tensor.\n",
        "* <font color='red'>`tensor[1, :]`</font>: Get the second row from the tensor.\n",
        "* For higher-dimensional tensors, the operations are the same. Such as <font color='red'>`tensor[:, 2, :]`</font>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3RkgB3m-N3P",
        "outputId": "4dd812c9-227e-428d-f278-c144a1d758f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original tensor\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Select only one element\n",
            "tensor(5)\n",
            "Select the second column\n",
            "tensor([2, 5, 8])\n",
            "Select the second row.\n",
            "tensor([4, 5, 6])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Using indexes to access values\n",
        "# ==============================================================================\n",
        "a = torch.arange(1, 10).reshape((3, 3))\n",
        "# The output\n",
        "# tensor([[1, 2, 3],\n",
        "#         [4, 5, 6],\n",
        "#         [7, 8, 9]])\n",
        "print(\"The original tensor\")\n",
        "print(a)\n",
        "\n",
        "print(\"Select only one element\")\n",
        "print(a[1,1])\n",
        "\n",
        "print(\"Select the second column\")\n",
        "print(a[:, 1])\n",
        "\n",
        "print(\"Select the second row.\")\n",
        "print(a[1, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yJ243nM-QNk"
      },
      "source": [
        "### Using `index_select`\n",
        "\n",
        "<font color='red'>`index_select`</font> requires the following parameters:\n",
        "\n",
        "* The first parameter is the tensor we want to select.\n",
        "* <font color='red'>`dim`</font>: It indicates the dimension in which we index.<br> In this example, the tensor is a 2-dimensions tensor. <font color='red'>`dim=0`</font> means the row, <font color='red'>`dim=1`</font> means the column.\n",
        "* <font color='red'>`index`</font>: The 1-D tensor containing the indices to index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whmAd35LAQwI",
        "outputId": "2961a21f-af2d-401d-f894-1b25db92f402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.arange(1, 10).reshape((3, 3))\n",
        "\n",
        "indices = torch.LongTensor([0, 2])\n",
        "result = torch.index_select(a, dim=0, index=indices)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtwiWLJsAR6D"
      },
      "source": [
        "### Using a mask\n",
        "\n",
        "The mask tensor is <font color='red'>`BoolTensor`</font>, which identifies which elements are chosen. The <font color='red'>`shape`</font> of the mask tensor and the original tensor doesn’t need to match, but they must be broadcastable.\n",
        "\n",
        "In short, PyTorch enables us to pass a tensor of Boolean type to <font color='red'>`masked_select`</font>, which selects desired elements from another tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4YvQknRA50w",
        "outputId": "7a236ba3-7683-4818-f949-f7a44a63d423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mask tensor is: \n",
            "tensor([[ True, False,  True],\n",
            "        [False, False,  True],\n",
            "        [ True, False, False]])\n",
            "The original tensor is: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "The result is tensor([1, 3, 6, 7])\n"
          ]
        }
      ],
      "source": [
        "a = torch.arange(1, 10).reshape((3, 3))\n",
        "\n",
        "mask = torch.BoolTensor([[True, False, True],\n",
        "                        [False, False, True],\n",
        "                        [True, False, False]])\n",
        "print(\"The mask tensor is: \\n{}\".format(mask))\n",
        "print(\"The original tensor is: \\n{}\".format(a))\n",
        "result = torch.masked_select(a, mask)\n",
        "print(\"The result is {}\".format(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbWf_jNDA7tO"
      },
      "source": [
        "## Changing the Tensor Shape\n",
        "\n",
        "### Reshaping a tensor\n",
        "\n",
        "`torch.reshape(t,shape)`\n",
        "- `t`: the tensor holding the data to be reshaped\n",
        "- `shape`: the new shape; typically a tuple: (2,4) to reshape the values into 2*4 tensor\n",
        "\n",
        "**Notice**:\n",
        "- within `shape`, we can use `-1` to let PyTorch **infer** the shape to match the number of elements<br>Check the below example "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mA-GLETBmZK",
        "outputId": "49afb089-6efb-4fd1-cc18-417021bab7e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original tensor\n",
            ".\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
            "The reshape tensor with shape (2, 4)\n",
            "\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "The reshape tensor with shape (2, -1)\n",
            "\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.arange(1, 9)\n",
        "print(\"The original tensor\\n.\")\n",
        "print(a)\n",
        "\n",
        "b = torch.reshape(a, (2, 4))\n",
        "print(\"The reshape tensor with shape (2, 4)\\n\")\n",
        "print(b)\n",
        "# ==============================================================================\n",
        "# Using -1 as a  dimension  makes the actual  dimension value  to be inferred to\n",
        "# match the number of values\n",
        "# ==============================================================================\n",
        "c = torch.reshape(a, (2, -1))\n",
        "print(\"The reshape tensor with shape (2, -1)\\n\")\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IRu-ITRBnIM"
      },
      "source": [
        "### Squeezing\n",
        "\n",
        "To remove the dimensions of 1 entry; for example, having a tensor of `(3,1,2)` like below, we want to remove the 2nd dimension, as it is not needed. We do so using `squeeze`\n",
        "\n",
        "* We can’t squeeze a dimension if the size is greater than 1.\n",
        "* We can squeeze multiple dimensions simultaneously in one function call. Nevertheless, it squeezes all of the dimensions, whose entries are 1s.\n",
        "\n",
        "**Parameters:**\n",
        "* <font color='red'>`input`</font>: The tensor we want to perform squeeze on.\n",
        "* <font color='red'>`dim`</font>: The dimension we want to perform squeeze on. It’s optional.<br>If not specified, it squeezes all the dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN1beWGBCGAg",
        "outputId": "0e48843e-c310-42a6-ced4-e766257c1bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original shape of a is torch.Size([3, 1, 2])\n",
            "The original a tensor is tensor([[[1., 1.]],\n",
            "\n",
            "        [[1., 1.]],\n",
            "\n",
            "        [[1., 1.]]])\n",
            "The new shape of a is torch.Size([3, 2])\n",
            "The new tensor is tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "The original shape of a is torch.Size([3, 1, 2, 1, 2])\n",
            "The original b tensor is tensor([[[[[1., 1.]],\n",
            "\n",
            "          [[1., 1.]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[1., 1.]],\n",
            "\n",
            "          [[1., 1.]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[1., 1.]],\n",
            "\n",
            "          [[1., 1.]]]]])\n",
            "The new shape of a is torch.Size([3, 2, 2])\n",
            "The new tensor is tensor([[[1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.]]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Create a tensor and squeeze it\n",
        "# ==============================================================================\n",
        "a = torch.ones((3, 1, 2))\n",
        "print(\"The original shape of a is {}\".format(a.shape))\n",
        "print(\"The original a tensor is {}\".format(a))\n",
        "\n",
        "a = torch.squeeze(a, dim=1)\n",
        "print(\"The new shape of a is {}\".format(a.shape))\n",
        "print(\"The new tensor is {}\".format(a))\n",
        "\n",
        "b = torch.ones((3,1,2,1,2))\n",
        "print(\"The original shape of a is {}\".format(b.shape))\n",
        "print(\"The original b tensor is {}\".format(b))\n",
        "\n",
        "b = torch.squeeze(b)\n",
        "print(\"The new shape of a is {}\".format(b.shape))\n",
        "print(\"The new tensor is {}\".format(b))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd4LSvdECG6i"
      },
      "source": [
        "### Un-squeezing\n",
        "The reverse of `squeeze()`, adding dimensions of 1.\n",
        "**Parameters:**\n",
        "* <font color='red'>`dim`</font>: This parameter indicates the index at which to insert the dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMXs4Cs_C3os",
        "outputId": "17c8fddc-9d2d-4240-a8f8-791e998404df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original shape of a is torch.Size([3, 3])\n",
            "The original a tensor is tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "The new shape of a is torch.Size([3, 1, 3])\n",
            "The new tensor is tensor([[[1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1.]]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Unsqueezing\n",
        "# ==============================================================================\n",
        "a = torch.ones((3, 3))\n",
        "print(\"The original shape of a is {}\".format(a.shape))\n",
        "print(\"The original a tensor is {}\".format(a))\n",
        "\n",
        "a = torch.unsqueeze(a, dim=1)\n",
        "print(\"The new shape of a is {}\".format(a.shape))\n",
        "print(\"The new tensor is {}\".format(a))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTvGou1PC4ke"
      },
      "source": [
        "### Transposing\n",
        "\n",
        "Transposing with respect to a particular two dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJUFdvD1DTPa",
        "outputId": "83390daf-f3cf-4c98-fce0-017f702bb4ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original shape of a is torch.Size([2, 4])\n",
            "The original tensor a is tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "The new shape of a is torch.Size([4, 2])\n",
            "The new tensor a is tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "The original shape of b is torch.Size([2, 4, 2])\n",
            "The original tensor b is tensor([[[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]]])\n",
            "The new shape of b is torch.Size([2, 2, 4])\n",
            "The new tensor b is tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Create a tensor and transpose two dimensions\n",
        "# ==============================================================================\n",
        "a = torch.ones((2, 4))\n",
        "print(\"The original shape of a is {}\".format(a.shape))\n",
        "print(\"The original tensor a is {}\".format(a))\n",
        "\n",
        "a = torch.transpose(a, 0, 1)\n",
        "print(\"The new shape of a is {}\".format(a.shape))\n",
        "print(\"The new tensor a is {}\".format(a))\n",
        "\n",
        "b = torch.ones((2, 4, 2))\n",
        "print(\"The original shape of b is {}\".format(b.shape))\n",
        "print(\"The original tensor b is {}\".format(b))\n",
        "\n",
        "b = torch.transpose(b, 1, 2)\n",
        "print(\"The new shape of b is {}\".format(b.shape))\n",
        "print(\"The new tensor b is {}\".format(b))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPcMUXeBECtH",
        "tags": []
      },
      "source": [
        "## Merging Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "XvzdJlKW5wZ1"
      },
      "source": [
        "### Concatenation\n",
        "\n",
        "<font color='red'>`torch.cat()`</font> can concatenate a sequence of tensors in a given dimension. All tensors should have the same shape. **Notice** that concatenation happens by extending the values of a dimension. No new dimensions is created. Check the below examples for further clarification \n",
        "\n",
        "* <font color='red'>`tensors`</font>: A list of tensors must have the same shape.\n",
        "* <font color='red'>`dim`</font>: The dimension over which the tensors are concatenated.<br>Take 2D tensors as an example, <font color='red'>`dim=0`</font> means the operation would be performed row-wise, w.r.t 1st dimension.<br><font color='red'>`dim=1`</font> means the operation would be performed column-wise, , w.r.t 2nd dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWoN6q17EitN",
        "outputId": "a88fabfe-370d-47ee-93d5-1328b376f7cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original tesnor a is\n",
            " tensor([[ 0.3645,  0.1179, -0.3338],\n",
            "        [ 1.2409, -1.2293, -0.4904],\n",
            "        [ 0.1263, -0.0732,  1.0363]])\n",
            "The shape of concatenating (a,a) is torch.Size([6, 3])\n",
            "The new tensor is\n",
            " tensor([[ 0.3645,  0.1179, -0.3338],\n",
            "        [ 1.2409, -1.2293, -0.4904],\n",
            "        [ 0.1263, -0.0732,  1.0363],\n",
            "        [ 0.3645,  0.1179, -0.3338],\n",
            "        [ 1.2409, -1.2293, -0.4904],\n",
            "        [ 0.1263, -0.0732,  1.0363]])\n",
            "The original tesnor b is\n",
            " tensor([[-0.5292,  0.6205,  1.7128],\n",
            "        [-1.2221, -1.1406,  1.1263],\n",
            "        [-1.7528, -0.5989, -2.3606]])\n",
            "The shape of result is torch.Size([3, 6])\n",
            "The new tensor is\n",
            " tensor([[-0.5292,  0.6205,  1.7128, -0.5292,  0.6205,  1.7128],\n",
            "        [-1.2221, -1.1406,  1.1263, -1.2221, -1.1406,  1.1263],\n",
            "        [-1.7528, -0.5989, -2.3606, -1.7528, -0.5989, -2.3606]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Concatenating tensors\n",
        "# ==============================================================================\n",
        "a = torch.randn((3, 3))\n",
        "print(\"The original tesnor a is\\n {}\".format(a))\n",
        "result = torch.cat((a, a), dim=0)\n",
        "print(\"The shape of concatenating (a,a) is {}\".format(result.shape))\n",
        "print(\"The new tensor is\\n {}\".format(result))\n",
        "\n",
        "b = torch.randn((3, 3))\n",
        "print(\"The original tesnor b is\\n {}\".format(b))\n",
        "result = torch.cat((b, b), dim=1)\n",
        "print(\"The shape of result is {}\".format(result.shape))\n",
        "print(\"The new tensor is\\n {}\".format(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STtYSl5UEoeh",
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Stacking\n",
        "\n",
        "<font color='red'>`torch.stack()`</font> concatenates the sequence of tensors along a **new dimension**.\n",
        "\n",
        "For example, there are two tensors with the shape (3, 4). We stack these two tensors with <font color='red'>`dim=1`</font>, then the shape of the return value would be (3, 2, 4). On the other hand, using `torch.cat` with `dim=1` produces a result whose shape is `(3,8)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODKtelzTFSmb",
        "outputId": "3c0b3db2-4b9a-4c0f-da8f-e3d30e3b0829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original tesnor a is\n",
            " tensor([[ 0.0695, -0.4278],\n",
            "        [-0.4861, -0.7959]])\n",
            "The original tesnor b is\n",
            " tensor([[-0.5204, -0.7523],\n",
            "        [ 2.2930,  0.9971]])\n",
            "The shape of result is torch.Size([2, 2, 2])\n",
            "The new tensor is\n",
            " tensor([[[ 0.0695, -0.4278],\n",
            "         [-0.5204, -0.7523]],\n",
            "\n",
            "        [[-0.4861, -0.7959],\n",
            "         [ 2.2930,  0.9971]]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Stacking tensors\n",
        "# ==============================================================================\n",
        "a = torch.randn((2, 2))\n",
        "b = torch.randn((2, 2))\n",
        "print(\"The original tesnor a is\\n {}\".format(a))\n",
        "print(\"The original tesnor b is\\n {}\".format(b))\n",
        "result = torch.stack((a, b), dim=1)\n",
        "print(\"The shape of result is {}\".format(result.shape))\n",
        "print(\"The new tensor is\\n {}\".format(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHLMFuCQFjXj"
      },
      "source": [
        "## Tensor Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMHHwo0z5wZ3"
      },
      "source": [
        "### Mathematical Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "12AlXCgp5wZ3"
      },
      "source": [
        "#### With Scalars\n",
        "In PyTorch, we perform mathematical operations with scalars in two ways:\n",
        "\n",
        "* using operators like <font color='red'>`+`</font>, <font color='red'>`-`</font>, and <font color='red'>`*`</font>.\n",
        "* using functions like <font color='red'>`add`</font>, <font color='red'>`sub`</font>, and <font color='red'>`mul`</font>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "q7tJmFH7F-bH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e14d105-f764-4f74-8d11-4b1443818ef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before adding: tensor([1, 2, 3])\n",
            "Adding 3 using '+': tensor([4, 5, 6])\n",
            "Adding 3 using 'add': tensor([4, 5, 6])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Adding a scalar to all the values of a tensor\n",
        "# ==============================================================================\n",
        "a = torch.tensor([1,2,3])\n",
        "b = a + 3\n",
        "c = a.add(3)\n",
        "print(\"Before adding: {}\".format(a))\n",
        "print(\"Adding 3 using '+': {}\".format(b))\n",
        "print(\"Adding 3 using 'add': {}\".format(c))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r_iL7NmGLOm"
      },
      "source": [
        "PyTorch supports most of the math functions under the native Python <font color='red'>`math`</font> module. You could find a complete list from the [official site](https://pytorch.org/docs/stable/torch.html#pointwise-ops)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "sOEkteNk5wZ3"
      },
      "source": [
        "##### In-place Operations\n",
        "We notice all the above operations are not in-place, so we cannot change the tensor values directly. If we would like to perform in-place operations, instead, we use the defined functions for it. Mostly, it is the same function with added `_` at its end. For example, `add` & `add_` and `sin` & `sin_`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhIfeVU05wZ4",
        "outputId": "40d15579-c890-4496-f8aa-90fb3b64ebd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:\n",
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
            "\n",
            "b:\n",
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# In-place operation\n",
        "# ==============================================================================\n",
        "a = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
        "print('a:')\n",
        "print(a)\n",
        "print(torch.sin(a))   # this operation creates a new tensor in memory\n",
        "print(a)              # a has not changed\n",
        "\n",
        "b = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
        "print('\\nb:')\n",
        "print(b)\n",
        "print(torch.sin_(b))  # note the underscore\n",
        "print(b)              # b has changed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx_I-d8u5wZ4",
        "outputId": "c5374f01-fa4f-45b5-c486-bc96940604cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0.9883, 0.4762],\n",
            "        [0.7242, 0.0776]])\n",
            "\n",
            "After adding:\n",
            "tensor([[1.9883, 1.4762],\n",
            "        [1.7242, 1.0776]])\n",
            "tensor([[1.9883, 1.4762],\n",
            "        [1.7242, 1.0776]])\n",
            "tensor([[0.9883, 0.4762],\n",
            "        [0.7242, 0.0776]])\n",
            "\n",
            "After multiplying\n",
            "tensor([[0.9768, 0.2268],\n",
            "        [0.5245, 0.0060]])\n",
            "tensor([[0.9768, 0.2268],\n",
            "        [0.5245, 0.0060]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# In-place operations\n",
        "# ==============================================================================\n",
        "a = torch.ones(2, 2)\n",
        "b = torch.rand(2, 2)\n",
        "\n",
        "print('Before:')\n",
        "print(a)\n",
        "print(b)\n",
        "print('\\nAfter adding:')\n",
        "print(a.add_(b))\n",
        "print(a)\n",
        "print(b)\n",
        "print('\\nAfter multiplying')\n",
        "print(b.mul_(b))\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDKyh07bGpEm",
        "tags": []
      },
      "source": [
        "#### Among Tensors\n",
        "\n",
        "We have two mathematical operators among tensors\n",
        "- **Element-wise**: using the same above operators and functions, like with scalars.<br>For example, `a+b` adds each element of `a` to its correspondence in `b`\n",
        "- **Matrix Operation**: here we do matrix multiplication between tensors using<br>Notice: matrix dimension constraints should hold when using these operations\n",
        "    - `mv`: multiplication between **matrix and vector** tensors\n",
        "    - `mm`: multiplication between **matrix and matrix** tensors\n",
        "    - `dot`: dot product of 2 **1D tensors**, vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncVwugk-G7do",
        "outputId": "3c041541-b7ca-4474-a8f6-87bfc6e62893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The multiple between a an b is tensor([ 2,  8, 18])\n",
            "The multiple between a an b is tensor([ 2,  8, 18])\n",
            "The multiple between e an f is tensor([[2, 4],\n",
            "        [6, 8]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Element wise operations\n",
        "# ==============================================================================\n",
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([2, 4, 6])\n",
        "\n",
        "c = a * b\n",
        "print(\"The multiple between a an b is {}\".format(c))\n",
        "\n",
        "c = a.mul(b)\n",
        "print(\"The multiple between a an b is {}\".format(c))\n",
        "\n",
        "e = torch.tensor([[1, 2], [3, 4]])\n",
        "f = torch.tensor([[2, 2], [2, 2]])\n",
        "\n",
        "g = e*f \n",
        "print(\"The multiple between e an f is {}\".format(g))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i803G40L5wZ5",
        "outputId": "33d0675d-026c-42e8-98c8-e569ba61106d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The matrix is \n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "==============================\n",
            "The vector is \n",
            "tensor([1., 2., 3., 4.])\n",
            "==============================\n",
            "The result is \n",
            "tensor([10., 10.])\n",
            "==============================\n",
            "The result is \n",
            "tensor([10., 10.])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Matrix-vector multiplication\n",
        "# ==============================================================================\n",
        "mat = torch.ones((2, 4))\n",
        "print(\"The matrix is \\n{}\".format(mat))\n",
        "\n",
        "print(\"=\"*30)\n",
        "vec = torch.tensor([1, 2, 3, 4], dtype=torch.float)\n",
        "print(\"The vector is \\n{}\".format(vec))\n",
        "\n",
        "print(\"=\"*30)\n",
        "result = mat.mv(vec)\n",
        "print(\"The result is \\n{}\".format(result))\n",
        "\n",
        "print(\"=\"*30)\n",
        "result = torch.mv(mat, vec)\n",
        "print(\"The result is \\n{}\".format(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOpFualj5wZ6",
        "outputId": "8e3ce276-c66d-4475-902c-f69f04e076c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result is \n",
            " tensor([[4., 4., 4.],\n",
            "        [4., 4., 4.]])\n",
            "==============================\n",
            "The result is \n",
            " tensor([[4., 4., 4.],\n",
            "        [4., 4., 4.]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Matrix-matrix multiplication\n",
        "# ==============================================================================\n",
        "mat1 = torch.ones((2, 4))\n",
        "mat2 = torch.ones((4, 3))\n",
        "\n",
        "result = torch.mm(mat1, mat2)\n",
        "print(\"The result is \\n {}\".format(result))\n",
        "\n",
        "print(\"=\"*30)\n",
        "result = mat1.mm(mat2)\n",
        "print(\"The result is \\n {}\".format(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_Lu_-wy5wZ6",
        "outputId": "84071149-c145-4542-ffa5-e0a5b3aa0fbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result is \n",
            " 40\n",
            "==============================\n",
            "The result is \n",
            " 40\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# vector-vector multiplication using dot product\n",
        "# ==============================================================================\n",
        "vec1 = torch.tensor([1, 2, 3, 4])\n",
        "vec2 = torch.tensor([2, 3, 4, 5])\n",
        "\n",
        "result = vec1.dot(vec2)\n",
        "print(\"The result is \\n {}\".format(result))\n",
        "\n",
        "print(\"=\"*30)\n",
        "result = torch.dot(vec1, vec2)\n",
        "print(\"The result is \\n {}\".format(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgEjOu045wZ7"
      },
      "source": [
        "### Reduction Operations\n",
        "These are operations performed on a particular dimension, default is `0`, over the group of values; it includes statistical and other operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u-PZwcrHR6P"
      },
      "source": [
        "|Function Name | Purpose|\n",
        "|---|---|\n",
        "|`mean`|\tGet the mean value of the tensor in the given dimension.|\n",
        "|`sum`|\tSum the values of the tensor over the given dimension.|\n",
        "|`median`|\tGet the median value of tensor in the given dimension.|\n",
        "|`std`|\tCompute the standard deviation of the tensor over the given dimension.|\n",
        "|`prod`|\tProduct the values of the tensor over the given dimension.|\n",
        "|`cumsum`|\tCumulative sum of values of the tensor over the given dimension.|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHWmhN2ZIK4u",
        "outputId": "82aa3c9e-f5ae-4ce0-e60f-67abf0cc9ace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original tensor is \n",
            " tensor([[ 0.2359,  0.7787, -0.1732, -0.1074],\n",
            "        [ 1.9456,  0.4525,  0.1014,  0.3339],\n",
            "        [ 1.6279,  1.0423, -0.6320,  1.4610]])\n",
            "==============================\n",
            "The mean value of dim=1 \n",
            " tensor([0.1835, 0.7084, 0.8748])\n",
            "==============================\n",
            "The sum value of dim=0 \n",
            " tensor([ 3.8094,  2.2735, -0.7038,  1.6875])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Use the mean and sum to demonstrate their usage\n",
        "# ==============================================================================\n",
        "a = torch.randn((3,4))\n",
        "print(\"The original tensor is \\n {}\".format(a))\n",
        "\n",
        "# ==============================================================================\n",
        "# We compute the mean of all the values per column, dim 1\n",
        "# ==============================================================================\n",
        "print(\"=\"*30)\n",
        "b = torch.mean(a, dim=1)\n",
        "print(\"The mean value of dim=1 \\n {}\".format(b))\n",
        "\n",
        "# ==============================================================================\n",
        "# We sum all the values per row, dim 0\n",
        "# ==============================================================================\n",
        "print(\"=\"*30)\n",
        "c = torch.sum(a, dim=0)\n",
        "print(\"The sum value of dim=0 \\n {}\".format(c))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE2-5ec65wZ8"
      },
      "source": [
        "### Logical Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMRdaNBmIImG"
      },
      "source": [
        "|Function\t| Purpose|\n",
        "|---|---|\n",
        "|`lt`|\tLess than|\n",
        "|`le`|\tLess than or equal to|\n",
        "|`gt`|\tGreater than|\n",
        "|`ge`|\tGreater than or equal to|\n",
        "|`eq`|\tEqual to|\n",
        "|`ne`|\tNot Equal to|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viavjDqDI_ar",
        "outputId": "0ca45c86-1410-4a50-a029-5ab82fb1252e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original tensor is \n",
            " tensor([[ 2.3482,  0.1805, -0.5357,  1.2000],\n",
            "        [-0.6827, -0.1046, -0.9332, -0.8011],\n",
            "        [-0.1352,  0.0627,  0.9978, -1.1855]])\n",
            "==============================\n",
            "The comparison between a tensor and a single value.\n",
            "\n",
            "The element is less than 0.5 \n",
            " tensor([[False,  True,  True, False],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True, False,  True]])\n",
            "==============================\n",
            "The comparison between two tensors.\n",
            "\n",
            "The comparison result between tesnor a and c \n",
            " tensor([[ True, False,  True,  True],\n",
            "        [ True, False, False,  True],\n",
            "        [False,  True,  True, False]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Demonstrate the logical operations\n",
        "# ==============================================================================\n",
        "a = torch.randn((3,4))\n",
        "print(\"The original tensor is \\n {}\".format(a))\n",
        "\n",
        "print(\"=\"*30)\n",
        "print(\"The comparison between a tensor and a single value.\\n\")\n",
        "b = torch.lt(a, 0.5)\n",
        "print(\"The element is less than 0.5 \\n {}\".format(b))\n",
        "\n",
        "print(\"=\"*30)\n",
        "c = torch.randn((3, 4))\n",
        "print(\"The comparison between two tensors.\\n\")\n",
        "d = torch.gt(a, c)\n",
        "print(\"The comparison result between tesnor a and c \\n {}\".format(d))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPJAdIuOK09X"
      },
      "source": [
        "## Saving and Loading Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5vy7bKm5wZ9"
      },
      "source": [
        "### Saving a single tensor\n",
        "\n",
        "The **model weights**, as we will see, are mostly **saved** to be re-used without performing training again. In such case, we would typically store the tensors representing the weights. Below is a demonstration of how to save a single tensor. The file extension is usually `.pt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "bzghSzVmLEye"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Saving the file <a> into a location: here ./tensor.pt\n",
        "# ==============================================================================\n",
        "a = torch.tensor([1, 2, 3])\n",
        "torch.save(a, \"./tensor.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW4Rb9HsLOcp"
      },
      "source": [
        "### Loading tensors from file\n",
        "\n",
        "It is simply the reverse of the saving operation. We just need to specify the location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ktw7Hw8LYPU",
        "outputId": "28ceb076-d0ea-4e7b-aa68-4b12038963cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensor b is tensor([1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Loading the previously saved tesnor\n",
        "# ==============================================================================\n",
        "b = torch.load(\"./tensor.pt\")\n",
        "print(\"The tensor b is {}\".format(b))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohlp0_1hLiaJ"
      },
      "source": [
        "### Saving Multiple Tensors\n",
        "\n",
        "We use `save` not only to store a tensor, but also to save other stuctures like dictionaries. Below we use it to save a dictionary of multiple tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMgD3orRLta3",
        "outputId": "1fa6c5df-0ba3-4488-d240-59dd5c2a6d51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensor map is {'t1': tensor([1, 2, 3]), 't2': tensor([2, 4, 6])}\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Use save to store a dictionary of tensors\n",
        "# ==============================================================================\n",
        "# m is a key-value structure to store variables.\n",
        "# In this example, \"t1\" is the key, and tensor([1, 2, 3]) is the value.\n",
        "m = {}\n",
        "m[\"t1\"] = torch.tensor([1, 2, 3])\n",
        "m[\"t2\"] = torch.tensor([2, 4, 6])\n",
        "torch.save(m, \"./m_tensor.pt\")\n",
        "\n",
        "m2 = torch.load(\"./m_tensor.pt\")\n",
        "print(\"The tensor map is {}\".format(m2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGLMwAXdMq7_"
      },
      "source": [
        "## GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4LpnZAq5wZ_"
      },
      "source": [
        "First, we should check whether a GPU is available, with the <font color='red'>`is_available()`</font> method.\n",
        "\n",
        "**Note: If you do not have a CUDA-compatible GPU and CUDA drivers installed, the executable cells in this section will not execute any GPU-related code.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6msIo-KPLLx",
        "outputId": "78362faa-0c40-41f2-ad11-c326805db96b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry, CPU only.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Checking whether a GPU is available\n",
        "# ==============================================================================\n",
        "if torch.cuda.is_available():\n",
        "    print('We have a GPU!')\n",
        "else:\n",
        "    print('Sorry, CPU only.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imlkRnehPRAh"
      },
      "source": [
        "Once we've determined that one or more GPUs is available, we need to put our data someplace where the GPU can see it. Your CPU does computation on data in your computer's RAM. Your GPU has dedicated memory attached to it. Whenever you want to perform a computation on a device, you must move *all* the data needed for that computation to memory accessible by that device. (Colloquially, \"moving the data to memory accessible by the GPU\" is shorted to, \"moving the data to the GPU\".)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miq0O0V65waA"
      },
      "source": [
        "### Creating Tensor on GPU\n",
        "We can specify the tensor in which we would like to create our tensor on using the `device` argument as below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHFTTvx9PZJD",
        "outputId": "d3ecd0ad-fe2d-4584-d334-a54fab6b2067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry, CPU only.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Creating a tensor on a particular device\n",
        "# ==============================================================================\n",
        "if torch.cuda.is_available():\n",
        "    gpu_rand = torch.rand(2, 2, device='cuda')\n",
        "    print(gpu_rand)\n",
        "else:\n",
        "    print('Sorry, CPU only.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3QBz5wrPleN"
      },
      "source": [
        "By default, new tensors are created on the CPU, so we have to specify when we want to create our tensor on the GPU with the optional <font color='red'>`device`</font> argument. You can see when we print the new tensor, PyTorch informs us which device it's on (if it's not on CPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RjFGZigP4QB",
        "outputId": "511e5149-dd88-4364-aee5-0c5c3bea9456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "tensor([[0.1986, 0.1779],\n",
            "        [0.6366, 0.2301]])\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Store the available device in a string to be used within your code\n",
        "# ==============================================================================\n",
        "if torch.cuda.is_available():\n",
        "    my_device = torch.device('cuda')\n",
        "else:\n",
        "    my_device = torch.device('cpu')\n",
        "print('Device: {}'.format(my_device))\n",
        "\n",
        "x = torch.rand(2, 2, device=my_device)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIcAeiaV5waA"
      },
      "source": [
        "You can query the number of GPUs with <font color='red'>`torch.cuda.device_count()`</font>. If you have more than one GPU, you can specify them by index: <font color='red'>`device='cuda:0'`</font>, <font color='red'>`device='cuda:1'`</font>, etc. That is if you have multiple GPUs, then you can use <font color='red'>`cuda:0`</font> referring to 1st one, <font color='red'>`cuda:1`</font> referring to 2nd, or <font color='red'>`cuda:2`</font> to refer to the 3rd, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G49xVxIyP_jh"
      },
      "source": [
        "### Casting to different device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twqZ5SIt5waC"
      },
      "source": [
        "We can use `to` to change a tensor from device to another"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "FEG-BWGPQESB"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Change the tensor from CPU to GPU if it exists\n",
        "# ==============================================================================\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "a = torch.tensor([1, 2, 3])\n",
        "c = a.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRSwljaXQSeC"
      },
      "source": [
        "**Note**: *all of the tensors must be on the same device*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrbssveoQz0g"
      },
      "source": [
        "### Getting device\n",
        "\n",
        "- `device` is used to return the tensor device\n",
        "- `is_cdua` is a boolean value to indicate whether the tensor is on the GPU or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-9BMZEyQP4U",
        "outputId": "02f1d7f0-e9c9-4621-c789-8a982f84d4bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The GPU is False.\n",
            "\n",
            "The device is cpu.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Check the device\n",
        "# ==============================================================================\n",
        "a = torch.randn((2, 3, 4), dtype=torch.float)\n",
        "print(\"The GPU is {}.\\n\".format(a.is_cuda))\n",
        "print(\"The device is {}.\".format(a.device))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Lab 2: Tensor Operations.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}